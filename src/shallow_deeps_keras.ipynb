{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refs\n",
    "\n",
    "https://medium.com/@nachiketadave/convolutional-neural-networks-with-tensorflow-2-0-d13f3a3148aa\n",
    "\n",
    "https://deepai.org/publication/learning-deep-features-for-one-class-classification\n",
    "\n",
    "https://www.kaggle.com/tongpython/cat-and-dog/data?select=test_set\n",
    "\n",
    "\n",
    "How to Install TensorFlow with GPU Support on Windows 10 (Without Installing CUDA) UPDATED!\n",
    "https://www.pugetsystems.com/labs/hpc/How-to-Install-TensorFlow-with-GPU-Support-on-Windows-10-Without-Installing-CUDA-UPDATED-1419/\n",
    "\n",
    "You may need to set env var TF_FORCE_GPU_ALLOW_GROWTH to True to use GPU\n",
    "https://github.com/tensorflow/tensorflow/issues/41146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.image as img\n",
    "from os import listdir\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "dog_img = []\n",
    "cat_img = []\n",
    "dog_add = '..\\\\dat\\\\cats_and_dogs\\\\training_set\\\\dogs'\n",
    "cat_add = '..\\\\dat\\\\cats_and_dogs\\\\training_set\\\\cats'\n",
    "add = [dog_add, cat_add]\n",
    "max_count = 500\n",
    "target_size = [256, 256]\n",
    "for i in add:\n",
    "    count = 1\n",
    "    for filename in listdir(i):\n",
    "        print(\".\", end=\"\")\n",
    "        image_data = img.imread(i + '\\\\' + filename)\n",
    "\n",
    "        original_image = Image.fromarray(np.uint8(image_data))\n",
    "        resized_image = original_image.resize(target_size)        \n",
    "        resized_image = np.array(resized_image)\n",
    "\n",
    "        if i == dog_add:\n",
    "            dog_img.append(resized_image)\n",
    "        else:\n",
    "            cat_img.append(resized_image)\n",
    "\n",
    "        count += 1\n",
    "        if count > max_count:\n",
    "            break\n",
    "\n",
    "    print()\n",
    "\n",
    "#creating labels for images\n",
    "img_labels = [0]*len(dog_img) + [1]*len(cat_img)\n",
    "all_img = dog_img + cat_img\n",
    "labels = {0:\"Dog\" , 1:\"Cat\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image, title):\n",
    "    _, ax = plt.subplots()\n",
    "    ax.imshow(np.uint8(image))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "# show one of the images of class 0\n",
    "index = 6\n",
    "show_image(all_img[index], \"Class = \" + str(np.squeeze(img_labels[index])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show one of the images of class 1\n",
    "index = len(cat_img) + 100\n",
    "show_image(all_img[index], \"Class = \" + str(np.squeeze(img_labels[index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Training and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_0, X_test_0, y_train, y_test = train_test_split(\n",
    "    all_img[:], img_labels[:], test_size=0.20)\n",
    "\n",
    "#converting X_test and X_train to numpy array (currently they are list)\n",
    "X_train_0 = np.asarray(X_train_0)\n",
    "y_train = np.asarray(y_train)\n",
    "X_test_0 = np.asarray(X_test_0)\n",
    "y_test = np.asarray(y_test)\n",
    "\n",
    "print(\"X_train_0 shape:\" + str(X_train_0.shape))\n",
    "print(\"y_train shape:\" + str(y_train.shape))\n",
    "print(\"X_test_0 shape:\" + str(X_test_0.shape))\n",
    "print(\"y_test shape:\" + str(y_test.shape))\n",
    "\n",
    "import tf_utils as utils\n",
    "Y_train = utils.convert_to_one_hot(np.uint(y_train), 2).T\n",
    "Y_test = utils.convert_to_one_hot(np.uint(y_test), 2).T\n",
    "\n",
    "print(\"Y_train shape:\" + str(Y_train.shape))\n",
    "print(\"Y_test shape:\" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_random_image(width=256, height=256, block_size=32):\n",
    "    w = int(width/block_size)\n",
    "    h = int(height/block_size)\n",
    "    \n",
    "    rand_pixels = [random.randint(0, 255) for _ in range(w*h*3)]\n",
    "    rand_pixels_as_bytes = bytes(rand_pixels)\n",
    "    random_image = Image.frombytes('RGB', (w, h), rand_pixels_as_bytes)\n",
    "    random_image = random_image.resize((width, height))\n",
    "    \n",
    "    return random_image\n",
    "\n",
    "random_image_test = generate_random_image()\n",
    "show_image(random_image_test, \"Randomly generated image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1 = X_train_0.copy()\n",
    "\n",
    "modify = False\n",
    "if modify:\n",
    "    for i in range(len(X_train_1)):\n",
    "        if y_train[i] == 1:\n",
    "            random_image = generate_random_image(width=256, height=256, block_size=64)\n",
    "            X_train_1[i] = np.asarray(random_image)\n",
    "\n",
    "if modify:\n",
    "    for i in range(len(X_train_1)):\n",
    "        if y_train[i] == 0:\n",
    "            show_image(X_train_1[i], \"0\")\n",
    "            break\n",
    "    for i in range(len(X_train_1)):\n",
    "        if y_train[i] == 1:\n",
    "            show_image(X_train_1[i], \"1\")\n",
    "            break\n",
    "\n",
    "X_train = X_train_1/255.\n",
    "X_test = X_test_0/255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initiating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "AlexNet_model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(96,(11,11),strides=4,activation='relu',data_format='channels_last',input_shape=(256,256,3)),\n",
    "    tf.keras.layers.MaxPool2D((3,3),strides=2),\n",
    "    tf.keras.layers.Conv2D(256,(5,5),padding='same',activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((3,3),strides=2),\n",
    "    tf.keras.layers.Conv2D(384,(3,3),padding='same',activation='relu'),\n",
    "    tf.keras.layers.Conv2D(256,(3,3),padding='same',activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((3,3),strides=2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(9216,activation='relu'),\n",
    "    tf.keras.layers.Dense(4096,activation='relu'),\n",
    "    tf.keras.layers.Dense(4096,activation='relu'),\n",
    "    tf.keras.layers.Dense(2,activation='softmax')\n",
    "])\n",
    "\n",
    "my_model_1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(8,(4,4),padding='same',activation='relu',input_shape=(256,256,3)),\n",
    "    tf.keras.layers.MaxPool2D((8,8),strides=8),\n",
    "    tf.keras.layers.Conv2D(32,(3,3),padding='same',activation='relu'),\n",
    "    tf.keras.layers.Conv2D(16,(2,2),padding='same',activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((4,4),strides=4),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256,activation='relu'),\n",
    "    tf.keras.layers.Dense(2,activation='softmax')\n",
    "])\n",
    "\n",
    "my_model_2 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(8,(4,4),padding='same',activation='relu',input_shape=(256,256,3)),\n",
    "    tf.keras.layers.MaxPool2D((8,8),strides=8),\n",
    "    tf.keras.layers.Conv2D(16,(2,2),padding='same',activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D((4,4),strides=4),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(2,activation='softmax')\n",
    "])\n",
    "\n",
    "model = my_model_2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compiling the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='Adam',\n",
    "    metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '..\\\\models\\\\shallowdeeps'\n",
    "model_dir = os.path.dirname(model_path)\n",
    "model_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    model_path,\n",
    "    save_weights_only=True,\n",
    "    verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fitting = model.fit(\n",
    "    X_train, Y_train, epochs=100, batch_size=64, validation_split=0.10,\n",
    "    shuffle=True, use_multiprocessing=True, callbacks=[model_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test, Y_test, use_multiprocessing=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting Training and Validation loss per epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "val_loss = fitting.history['val_loss']\n",
    "loss = fitting.history['loss']\n",
    "epochs = range(len(loss))\n",
    "plt.plot(epochs,loss)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.show()\n",
    "plt.plot(epochs,val_loss,'r')\n",
    "plt.title(\"Validation Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Pre-Trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use Trained Model to Perdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test) \n",
    "pred = np.argmax(pred, axis=1)\n",
    "#label = np.argmax(y_test, axis=0)[:5] \n",
    "\n",
    "print(pred) \n",
    "print(y_test)\n",
    "\n",
    "accuracy = np.sum(pred == y_test)/len(y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "pred = model.predict(X_train_0/255.) \n",
    "pred = np.argmax(pred, axis=1)\n",
    "#label = np.argmax(y_test, axis=0)[:5] \n",
    "accuracy = np.sum(pred == y_train)/len(y_train)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
